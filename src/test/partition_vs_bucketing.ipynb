{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "29b1bfdc", "cell_type": "markdown", "source": "\n# \ud83e\udde0 PySpark: Partitioning vs Bucketing (Local)\n\nIn this notebook, we explore **partitioning** and **bucketing** using PySpark, locally.\n\nWe'll cover:\n- \u2705 What is partitioning?\n- \u2705 What is bucketing?\n- \u2705 Use cases and differences\n- \u2705 Performance implications\n- \u2705 Sample code and test data\n\n---\n", "metadata": {}}, {"id": "e2e5073c", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nfrom pyspark.sql import SparkSession\nimport os\n\nspark = SparkSession.builder \\\n    .appName(\"Partitioning_vs_Bucketing\") \\\n    .master(\"local[*]\") \\\n    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n    .getOrCreate()\n\nspark.sparkContext.setLogLevel(\"WARN\")\n", "outputs": []}, {"id": "92f1f07d", "cell_type": "markdown", "source": "## \ud83d\udcc1 Step 1: Create Sample Dataset", "metadata": {}}, {"id": "172b2894", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nfrom pyspark.sql.functions import col, rand\nimport random\n\n# Create synthetic taxi-like data\ndf = spark.range(0, 1000000).withColumn(\"pickup_borough\", (col(\"id\") % 5).cast(\"string\"))\ndf = df.withColumn(\"vendor_id\", (col(\"id\") % 20).cast(\"string\"))\ndf = df.withColumn(\"fare_amount\", (col(\"id\") % 100) * rand())\n\ndf.write.mode(\"overwrite\").parquet(\"data/trips_raw\")\nprint(\"\u2705 Sample data written to 'data/trips_raw'\")\n", "outputs": []}, {"id": "e337e29d", "cell_type": "markdown", "source": "## \ud83d\udce6 Step 2: Partition the Dataset by `pickup_borough`", "metadata": {}}, {"id": "1e80568d", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\ndf.write.partitionBy(\"pickup_borough\").mode(\"overwrite\").parquet(\"data/trips_partitioned\")\nprint(\"\u2705 Data written with partitioning.\")\n", "outputs": []}, {"id": "75f2f2df", "cell_type": "markdown", "source": "## \ud83c\udfaf Step 3: Bucket the Dataset by `vendor_id` into 8 buckets", "metadata": {}}, {"id": "2517bd93", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nspark.sql(\"DROP TABLE IF EXISTS trips_bucketed\")\ndf.write.bucketBy(8, \"vendor_id\").sortBy(\"vendor_id\").mode(\"overwrite\").saveAsTable(\"trips_bucketed\")\nprint(\"\u2705 Data written with bucketing (as Hive table).\")\n", "outputs": []}, {"id": "d35a2e43", "cell_type": "markdown", "source": "## \ud83e\uddea Step 4: Compare Query Performance (Partitioned vs Bucketed)", "metadata": {}}, {"id": "1b7b4fa3", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nfrom time import time\n\n# Read partitioned\ndf_partitioned = spark.read.parquet(\"data/trips_partitioned\")\nstart = time()\ndf_partitioned.filter(\"pickup_borough = '2'\").groupBy(\"pickup_borough\").sum(\"fare_amount\").show()\nprint(f\"\u23f1\ufe0f Partitioned query took {time() - start:.2f} seconds\")\n\n# Read bucketed\nstart = time()\ndf_bucketed = spark.table(\"trips_bucketed\")\ndf_bucketed.filter(\"vendor_id = '5'\").groupBy(\"vendor_id\").sum(\"fare_amount\").show()\nprint(f\"\u23f1\ufe0f Bucketed query took {time() - start:.2f} seconds\")\n", "outputs": []}, {"id": "d7159eb7", "cell_type": "markdown", "source": "\n## \u2705 Summary: Partitioning vs Bucketing\n\n| Feature           | Partitioning                           | Bucketing                                 |\n|------------------|-----------------------------------------|--------------------------------------------|\n| Works on         | File system level (folders)             | Table level (Hive/Delta only)             |\n| Use case         | Filtering (pushdown)                    | Efficient joins / aggregations            |\n| Example column   | `pickup_borough`                        | `vendor_id`                               |\n| Performance gain | Partition pruning                       | Hash-based bucketing before shuffle       |\n| Format support   | \u2705 Parquet, Delta, ORC                  | \u274c Only Hive/Delta-compatible              |\n\n---\nNext: Broadcast vs Distributed Join \ud83d\udd04\n", "metadata": {}}]}