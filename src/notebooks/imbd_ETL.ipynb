{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9096c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "25/06/22 23:51:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/Users/aryan/Desktop/project/venv/lib/python3.9/site-packages/google/rpc/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark session started.\n"
     ]
    }
   ],
   "source": [
    "# STEP 0: Setup & Spark\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"../../\")))\n",
    "\n",
    "from config import settings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Synthetic_ETL_Pipeline\") \\\n",
    "    .config(\"spark.jars\", settings.JDBC_PATH) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Spark session started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724e6602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/22 23:51:22 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Reading title_basics\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+\n",
      "|    tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|    genre_1|  genre_2|        ingested_at|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+\n",
      "|tt32444893|tvEpisode|McCraw vs. Herrin...|McCraw vs. Herrin...|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|\n",
      "|tt32444895|tvEpisode|          Ed Genesis|          Ed Genesis|      0|     2019|     \\N|            \\N|Documentary|     NULL|2025-06-22 23:11:21|\n",
      "|tt32444899|tvEpisode|    Aikens vs. Brown|    Aikens vs. Brown|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|\n",
      "| tt3244490|tvEpisode|From Marshes to M...|From Marshes to M...|      0|     2002|     \\N|            21|     Action|Adventure|2025-06-22 23:11:21|\n",
      "|tt32444901|tvEpisode|     Orive vs. Stark|     Orive vs. Stark|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+\n",
      "only showing top 5 rows\n",
      "📄 Reading title_crew\n",
      "+----------+---------+---------+-------------------+\n",
      "|    tconst|directors|  writers|        ingested_at|\n",
      "+----------+---------+---------+-------------------+\n",
      "| tt2239602|nm0808310|       \\N|2025-06-22 23:12:07|\n",
      "| tt2239604|       \\N|nm0317102|2025-06-22 23:12:07|\n",
      "| tt2239606|       \\N|       \\N|2025-06-22 23:12:07|\n",
      "|tt22396070|nm0011612|nm0243626|2025-06-22 23:12:07|\n",
      "|tt22396074|nm0011612|nm0243626|2025-06-22 23:12:07|\n",
      "+----------+---------+---------+-------------------+\n",
      "only showing top 5 rows\n",
      "📄 Reading title_episode\n",
      "+----------+------------+------------+-------------+-------------------+\n",
      "|    tconst|parentTconst|seasonNumber|episodeNumber|        ingested_at|\n",
      "+----------+------------+------------+-------------+-------------------+\n",
      "|tt36958755|   tt2190581|          \\N|           \\N|2025-06-22 23:12:27|\n",
      "|tt36958759|   tt0312135|           1|            1|2025-06-22 23:12:27|\n",
      "| tt3695876|   tt1287391|           1|           76|2025-06-22 23:12:27|\n",
      "|tt36958761|   tt0185121|          \\N|           \\N|2025-06-22 23:12:27|\n",
      "|tt36958762|  tt32582878|           2|            6|2025-06-22 23:12:27|\n",
      "+----------+------------+------------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "📄 Reading title_akas\n",
      "+---------+--------+--------------------+------+--------+-----------+-------------+---------------+-------------------+\n",
      "|  titleId|ordering|               title|region|language|      types|   attributes|isOriginalTitle|        ingested_at|\n",
      "+---------+--------+--------------------+------+--------+-----------+-------------+---------------+-------------------+\n",
      "|tt0000001|       1|          Carmencita|    \\N|      \\N|   original|           \\N|              1|2025-06-22 23:12:43|\n",
      "|tt0000001|       2|          Carmencita|    DE|      \\N|         \\N|literal title|              0|2025-06-22 23:12:43|\n",
      "|tt0000001|       3|          Carmencita|    US|      \\N|imdbDisplay|           \\N|              0|2025-06-22 23:12:43|\n",
      "|tt0000001|       4|Carmencita - span...|    HU|      \\N|imdbDisplay|           \\N|              0|2025-06-22 23:12:43|\n",
      "|tt0000001|       5|          Καρμενσίτα|    GR|      \\N|imdbDisplay|           \\N|              0|2025-06-22 23:12:43|\n",
      "+---------+--------+--------------------+------+--------+-----------+-------------+---------------+-------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from config.spark_config import get_spark_session\n",
    "from config import settings\n",
    "\n",
    "# Step 3: Start Spark session\n",
    "spark = get_spark_session(app_name=\"Read_Parquet_Tuning\")\n",
    "\n",
    "# Step 4: Define Parquet folder path\n",
    "parquet_base = os.path.join(settings.BASE_DIR, \"data\", \"parquet_data\")\n",
    "\n",
    "# Step 5: Read each file\n",
    "parquet_files = {\n",
    "    \"title_basics\": os.path.join(parquet_base, \"title_basics.parquet\"),\n",
    "    \"title_crew\": os.path.join(parquet_base, \"title_crew.parquet\"),\n",
    "    \"title_episode\": os.path.join(parquet_base, \"title_episode.parquet\"),\n",
    "    \"title_akas\": os.path.join(parquet_base, \"title_akas.parquet\")\n",
    "}\n",
    "\n",
    "# Step 6: Show sample records\n",
    "for name, path in parquet_files.items():\n",
    "    print(f\"📄 Reading {name}\")\n",
    "    df = spark.read.parquet(path)\n",
    "    df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38166357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/22 23:51:28 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"../../\")))\n",
    "\n",
    "from config import settings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim\n",
    "import os\n",
    "from src.config.spark_config import get_spark_session\n",
    "custom_tuning = {\n",
    "    \"spark.executor.memory\": \"6g\",\n",
    "    \"spark.driver.memory\": \"4g\",\n",
    "    \"spark.executor.cores\": \"4\"\n",
    "}\n",
    "spark = get_spark_session(app_name=\"Read_Parquet_Tuning\", custom_config=custom_tuning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c295a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_base = os.path.join(settings.BASE_DIR, \"data\", \"parquet_data\")\n",
    "\n",
    "parquet_files = {\n",
    "    \"title_basics\": os.path.join(parquet_base, \"title_basics.parquet\"),\n",
    "    \"title_crew\": os.path.join(parquet_base, \"title_crew.parquet\"),\n",
    "    \"title_episode\": os.path.join(parquet_base, \"title_episode.parquet\"),\n",
    "    \"title_akas\": os.path.join(parquet_base, \"title_akas.parquet\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925acb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Reading title_basics\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- titleType: string (nullable = true)\n",
      " |-- primaryTitle: string (nullable = true)\n",
      " |-- originalTitle: string (nullable = true)\n",
      " |-- isAdult: string (nullable = true)\n",
      " |-- startYear: string (nullable = true)\n",
      " |-- endYear: string (nullable = true)\n",
      " |-- runtimeMinutes: string (nullable = true)\n",
      " |-- genre_1: string (nullable = true)\n",
      " |-- genre_2: string (nullable = true)\n",
      " |-- ingested_at: string (nullable = true)\n",
      "\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+-------+-------------------+\n",
      "|    tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|    genre_1|genre_2|        ingested_at|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+-------+-------------------+\n",
      "|tt32444915|    movie|Lightning in a Bo...|Lightning in a Bo...|      0|       \\N|     \\N|            90|Documentary|   NULL|2025-06-22 23:11:21|\n",
      "|tt32444916|    movie|     A Night of Fate|     A Night of Fate|      0|     2024|     \\N|            54|      Drama|   NULL|2025-06-22 23:11:21|\n",
      "|tt32444973|    movie|Mysterious Origin...|Mysterious Origin...|      0|     2024|     \\N|            \\N|Documentary|   NULL|2025-06-22 23:11:21|\n",
      "|tt32445107|    movie|             The Ten|             The Ten|      0|       \\N|     \\N|            \\N|    Musical|   NULL|2025-06-22 23:11:21|\n",
      "| tt3244512|    movie|   Charlie's Country|   Charlie's Country|      0|     2013|     \\N|           108|  Adventure|  Drama|2025-06-22 23:11:21|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+-------+-------------------+\n",
      "only showing top 5 rows\n",
      "🔢 Record count: 718108\n",
      "== Physical Plan ==\n",
      "* Filter (3)\n",
      "+- * ColumnarToRow (2)\n",
      "   +- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [11]: [tconst#124, titleType#125, primaryTitle#126, originalTitle#127, isAdult#128, startYear#129, endYear#130, runtimeMinutes#131, genre_1#132, genre_2#133, ingested_at#134]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/aryan/Desktop/project/data/parquet_data/title_basics.parquet]\n",
      "PushedFilters: [IsNotNull(titleType), EqualTo(titleType,movie)]\n",
      "ReadSchema: struct<tconst:string,titleType:string,primaryTitle:string,originalTitle:string,isAdult:string,startYear:string,endYear:string,runtimeMinutes:string,genre_1:string,genre_2:string,ingested_at:string>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [11]: [tconst#124, titleType#125, primaryTitle#126, originalTitle#127, isAdult#128, startYear#129, endYear#130, runtimeMinutes#131, genre_1#132, genre_2#133, ingested_at#134]\n",
      "\n",
      "(3) Filter [codegen id : 1]\n",
      "Input [11]: [tconst#124, titleType#125, primaryTitle#126, originalTitle#127, isAdult#128, startYear#129, endYear#130, runtimeMinutes#131, genre_1#132, genre_2#133, ingested_at#134]\n",
      "Condition : (isnotnull(titleType#125) AND (titleType#125 = movie))\n",
      "\n",
      "\n",
      "📄 Reading title_crew\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- directors: string (nullable = true)\n",
      " |-- writers: string (nullable = true)\n",
      " |-- ingested_at: string (nullable = true)\n",
      "\n",
      "+----------+---------+---------+-------------------+\n",
      "|    tconst|directors|  writers|        ingested_at|\n",
      "+----------+---------+---------+-------------------+\n",
      "| tt2239602|nm0808310|       \\N|2025-06-22 23:12:07|\n",
      "| tt2239604|       \\N|nm0317102|2025-06-22 23:12:07|\n",
      "| tt2239606|       \\N|       \\N|2025-06-22 23:12:07|\n",
      "|tt22396070|nm0011612|nm0243626|2025-06-22 23:12:07|\n",
      "|tt22396074|nm0011612|nm0243626|2025-06-22 23:12:07|\n",
      "+----------+---------+---------+-------------------+\n",
      "only showing top 5 rows\n",
      "🔢 Record count: 11729243\n",
      "== Physical Plan ==\n",
      "* ColumnarToRow (2)\n",
      "+- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [4]: [tconst#185, directors#186, writers#187, ingested_at#188]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/aryan/Desktop/project/data/parquet_data/title_crew.parquet]\n",
      "ReadSchema: struct<tconst:string,directors:string,writers:string,ingested_at:string>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [4]: [tconst#185, directors#186, writers#187, ingested_at#188]\n",
      "\n",
      "\n",
      "📄 Reading title_episode\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- parentTconst: string (nullable = true)\n",
      " |-- seasonNumber: string (nullable = true)\n",
      " |-- episodeNumber: string (nullable = true)\n",
      " |-- ingested_at: string (nullable = true)\n",
      "\n",
      "+----------+------------+------------+-------------+-------------------+\n",
      "|    tconst|parentTconst|seasonNumber|episodeNumber|        ingested_at|\n",
      "+----------+------------+------------+-------------+-------------------+\n",
      "|tt36958755|   tt2190581|          \\N|           \\N|2025-06-22 23:12:27|\n",
      "|tt36958759|   tt0312135|           1|            1|2025-06-22 23:12:27|\n",
      "| tt3695876|   tt1287391|           1|           76|2025-06-22 23:12:27|\n",
      "|tt36958761|   tt0185121|          \\N|           \\N|2025-06-22 23:12:27|\n",
      "|tt36958762|  tt32582878|           2|            6|2025-06-22 23:12:27|\n",
      "+----------+------------+------------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "🔢 Record count: 9025274\n",
      "== Physical Plan ==\n",
      "* ColumnarToRow (2)\n",
      "+- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [5]: [tconst#211, parentTconst#212, seasonNumber#213, episodeNumber#214, ingested_at#215]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/aryan/Desktop/project/data/parquet_data/title_episode.parquet]\n",
      "ReadSchema: struct<tconst:string,parentTconst:string,seasonNumber:string,episodeNumber:string,ingested_at:string>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [5]: [tconst#211, parentTconst#212, seasonNumber#213, episodeNumber#214, ingested_at#215]\n",
      "\n",
      "\n",
      "📄 Reading title_akas\n",
      "root\n",
      " |-- titleId: string (nullable = true)\n",
      " |-- ordering: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- types: string (nullable = true)\n",
      " |-- attributes: string (nullable = true)\n",
      " |-- isOriginalTitle: string (nullable = true)\n",
      " |-- ingested_at: string (nullable = true)\n",
      "\n",
      "+---------+--------+--------------------+------+--------+-----------+-------------+---------------+-------------------+\n",
      "|  titleId|ordering|               title|region|language|      types|   attributes|isOriginalTitle|        ingested_at|\n",
      "+---------+--------+--------------------+------+--------+-----------+-------------+---------------+-------------------+\n",
      "|tt0000001|       1|          Carmencita|    \\N|      \\N|   original|           \\N|              1|2025-06-22 23:12:43|\n",
      "|tt0000001|       2|          Carmencita|    DE|      \\N|         \\N|literal title|              0|2025-06-22 23:12:43|\n",
      "|tt0000001|       3|          Carmencita|    US|      \\N|imdbDisplay|           \\N|              0|2025-06-22 23:12:43|\n",
      "|tt0000001|       4|Carmencita - span...|    HU|      \\N|imdbDisplay|           \\N|              0|2025-06-22 23:12:43|\n",
      "|tt0000001|       5|          Καρμενσίτα|    GR|      \\N|imdbDisplay|           \\N|              0|2025-06-22 23:12:43|\n",
      "+---------+--------+--------------------+------+--------+-----------+-------------+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "🔢 Record count: 52399723\n",
      "== Physical Plan ==\n",
      "* ColumnarToRow (2)\n",
      "+- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [9]: [titleId#242, ordering#243, title#244, region#245, language#246, types#247, attributes#248, isOriginalTitle#249, ingested_at#250]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/aryan/Desktop/project/data/parquet_data/title_akas.parquet]\n",
      "ReadSchema: struct<titleId:string,ordering:string,title:string,region:string,language:string,types:string,attributes:string,isOriginalTitle:string,ingested_at:string>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [9]: [titleId#242, ordering#243, title#244, region#245, language#246, types#247, attributes#248, isOriginalTitle#249, ingested_at#250]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "for name, path in parquet_files.items():\n",
    "    print(f\"📄 Reading {name}\")\n",
    "\n",
    "    # Pushdown predicate\n",
    "    df = spark.read \\\n",
    "        .option(\"spark.sql.parquet.filterPushdown\", \"true\") \\\n",
    "        .parquet(path)\n",
    "\n",
    "    # Filter as early as possible\n",
    "    if \"titleType\" in df.columns:\n",
    "        df = df.filter(col(\"titleType\") == \"movie\")\n",
    "\n",
    "    # Print schema and show top rows\n",
    "    df.printSchema()\n",
    "    df.show(5)\n",
    "\n",
    "    # Example: count to test lazy eval and plan\n",
    "    print(\"🔢 Record count:\", df.count())\n",
    "\n",
    "    # Performance plan\n",
    "    df.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387e98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c8c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
