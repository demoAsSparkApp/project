{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15a5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"../../\")))\n",
    "\n",
    "from config import settings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim\n",
    "import os\n",
    "from src.config.spark_config import get_spark_session\n",
    "\n",
    "\n",
    "from src.config.spark_config import get_spark_session\n",
    "custom_config = {\n",
    "    \"spark.executor.memory\": \"6g\",\n",
    "    \"spark.driver.memory\": \"4g\",\n",
    "    \"spark.executor.cores\": \"4\",\n",
    "    \"spark.sql.shuffle.partitions\": \"8\",\n",
    "    \"spark.default.parallelism\": \"8\",\n",
    "    \"spark.sql.adaptive.enabled\": \"true\",\n",
    "    \"spark.sql.autoBroadcastJoinThreshold\": \"104857600\",  # 100MB\n",
    "    \"spark.speculation\": \"true\"\n",
    "}\n",
    "spark = get_spark_session(\"IMDB_Tuning_Demo\", custom_config)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# Optional: custom tuning for this session\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Define Parquet folder path\n",
    "parquet_base = os.path.join(settings.BASE_DIR, \"data\", \"parquet_data\")\n",
    "\n",
    "# ✅ Cell 2: Load IMDB Parquet Data\n",
    "import os\n",
    "from config import settings\n",
    "\n",
    "parquet_base = os.path.join(settings.BASE_DIR, \"data\", \"parquet_data\")\n",
    "title_basics = spark.read.parquet(os.path.join(parquet_base, \"title_basics.parquet\"))\n",
    "title_ratings = spark.read.parquet(os.path.join(parquet_base, \"title_ratings.parquet\"))\n",
    "title_akas = spark.read.parquet(os.path.join(parquet_base, \"title_akas.parquet\"))\n",
    "title_crew = spark.read.parquet(os.path.join(parquet_base, \"title_crew.parquet\"))\n",
    "name_basics = spark.read.parquet(os.path.join(parquet_base, \"name_basics.parquet\"))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb755e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# groupByKey() vs reduceByKey() Demo\n",
    "rdd = title_ratings.select(\"tconst\", \"averageRating\").rdd.map(lambda row: (row[0], float(row[1])))\n",
    "grouped = rdd.groupByKey().mapValues(lambda x: sum(x)/len(x)).take(5)\n",
    "reduced = rdd.mapValues(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(lambda a, b: (a[0]+b[0], a[1]+b[1])) \\\n",
    "              .mapValues(lambda x: x[0]/x[1]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e89de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|averageRating|count|\n",
      "+-------------+-----+\n",
      "|          6.5|35207|\n",
      "|          5.3|15551|\n",
      "|          7.4|57046|\n",
      "|          6.1|27237|\n",
      "|          5.9|22282|\n",
      "|          4.7| 9013|\n",
      "|          5.1|12126|\n",
      "|          4.2| 6968|\n",
      "|          5.6|22139|\n",
      "|          4.9| 9782|\n",
      "|          4.8|11772|\n",
      "|          4.4| 7907|\n",
      "|          3.6| 4079|\n",
      "|          3.4| 3313|\n",
      "|          4.0| 5792|\n",
      "|          3.8| 4802|\n",
      "|          3.0| 2417|\n",
      "|          6.4|37743|\n",
      "|          4.3| 6290|\n",
      "|          3.9| 4032|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# ✅ Cell 4: Change Shuffle Partitions Effect\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"2\")\n",
    "title_ratings.groupBy(\"averageRating\").count().show()\n",
    "# ✅ Lower partitions can improve performance for small datasets but may bottleneck large jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1844e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+---------+\n",
      "|    tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|    genre_1|  genre_2|        ingested_at|title_len|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+---------+\n",
      "|tt32444893|tvEpisode|McCraw vs. Herrin...|McCraw vs. Herrin...|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|       21|\n",
      "|tt32444895|tvEpisode|          Ed Genesis|          Ed Genesis|      0|     2019|     \\N|            \\N|Documentary|     NULL|2025-06-22 23:11:21|       10|\n",
      "|tt32444899|tvEpisode|    Aikens vs. Brown|    Aikens vs. Brown|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|       16|\n",
      "| tt3244490|tvEpisode|From Marshes to M...|From Marshes to M...|      0|     2002|     \\N|            21|     Action|Adventure|2025-06-22 23:11:21|       32|\n",
      "|tt32444901|tvEpisode|     Orive vs. Stark|     Orive vs. Stark|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|       15|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "def title_length(title): return len(title or \"\")\n",
    "length_udf = udf(title_length, IntegerType())\n",
    "title_basics.withColumn(\"title_len\", length_udf(title_basics.primaryTitle)).show(5)\n",
    "# ❌ Python UDFs are slow and break optimizations.\n",
    "# ✅ Cell 6: Use Built-in Functions Instead\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da338945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+---------+\n",
      "|    tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|    genre_1|  genre_2|        ingested_at|title_len|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+---------+\n",
      "|tt32444893|tvEpisode|McCraw vs. Herrin...|McCraw vs. Herrin...|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|       21|\n",
      "|tt32444895|tvEpisode|          Ed Genesis|          Ed Genesis|      0|     2019|     \\N|            \\N|Documentary|     NULL|2025-06-22 23:11:21|       10|\n",
      "|tt32444899|tvEpisode|    Aikens vs. Brown|    Aikens vs. Brown|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|       16|\n",
      "| tt3244490|tvEpisode|From Marshes to M...|From Marshes to M...|      0|     2002|     \\N|            21|     Action|Adventure|2025-06-22 23:11:21|       32|\n",
      "|tt32444901|tvEpisode|     Orive vs. Stark|     Orive vs. Stark|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|       15|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "title_basics.withColumn(\"title_len\", length(title_basics.primaryTitle)).show(5)\n",
    "# ✅ Built-in functions are optimized and faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a69da8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------+\n",
      "|    tconst|        primaryTitle|averageRating|\n",
      "+----------+--------------------+-------------+\n",
      "| tt8100968|        Episode #1.1|         10.0|\n",
      "|tt14049104|Filmmaker Jhon Ja...|         10.0|\n",
      "| tt0281732| Closed for Business|         10.0|\n",
      "|tt14044668|Interview with Fi...|         10.0|\n",
      "|tt26425618|       Episode #1.28|         10.0|\n",
      "+----------+--------------------+-------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ✅ Cell 7: Use Broadcast Joins for Small Tables\n",
    "from pyspark.sql.functions import broadcast\n",
    "joined_df = title_basics.join(broadcast(title_ratings), \"tconst\", \"left\") \\\n",
    "    .select(title_basics.tconst, title_basics.primaryTitle, title_ratings.averageRating) \\\n",
    "    .orderBy(\"averageRating\", ascending=False)\n",
    "joined_df.show(5)\n",
    "# ✅ Broadcast joins are efficient for small tables, reducing shuffle overhead.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b55f3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+---------+\n",
      "|    tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|    genre_1|  genre_2|        ingested_at|title_len|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+---------+\n",
      "|tt32444893|tvEpisode|McCraw vs. Herrin...|McCraw vs. Herrin...|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|       21|\n",
      "|tt32444895|tvEpisode|          Ed Genesis|          Ed Genesis|      0|     2019|     \\N|            \\N|Documentary|     NULL|2025-06-22 23:11:21|       10|\n",
      "|tt32444899|tvEpisode|    Aikens vs. Brown|    Aikens vs. Brown|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|       16|\n",
      "| tt3244490|tvEpisode|From Marshes to M...|From Marshes to M...|      0|     2002|     \\N|            21|     Action|Adventure|2025-06-22 23:11:21|       32|\n",
      "|tt32444901|tvEpisode|     Orive vs. Stark|     Orive vs. Stark|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|       15|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ Cell 7: Pandas UDF with Arrow\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "import pandas as pd\n",
    "@pandas_udf(\"int\")\n",
    "def pandas_title_len(s: pd.Series) -> pd.Series:\n",
    "    return s.str.len()\n",
    "title_basics.withColumn(\"title_len\", pandas_title_len(title_basics.primaryTitle)).show(5)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce9ba23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>ingested_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt32444893</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>McCraw vs. Herrington</td>\n",
       "      <td>McCraw vs. Herrington</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Reality-TV</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-06-22 23:11:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt32444895</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Ed Genesis</td>\n",
       "      <td>Ed Genesis</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-06-22 23:11:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt32444899</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Aikens vs. Brown</td>\n",
       "      <td>Aikens vs. Brown</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Reality-TV</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-06-22 23:11:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt3244490</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>From Marshes to Mountain Heights</td>\n",
       "      <td>From Marshes to Mountain Heights</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>\\N</td>\n",
       "      <td>21</td>\n",
       "      <td>Action</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>2025-06-22 23:11:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt32444901</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Orive vs. Stark</td>\n",
       "      <td>Orive vs. Stark</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Reality-TV</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-06-22 23:11:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tconst  titleType                      primaryTitle  \\\n",
       "0  tt32444893  tvEpisode             McCraw vs. Herrington   \n",
       "1  tt32444895  tvEpisode                        Ed Genesis   \n",
       "2  tt32444899  tvEpisode                  Aikens vs. Brown   \n",
       "3   tt3244490  tvEpisode  From Marshes to Mountain Heights   \n",
       "4  tt32444901  tvEpisode                   Orive vs. Stark   \n",
       "\n",
       "                      originalTitle isAdult startYear endYear runtimeMinutes  \\\n",
       "0             McCraw vs. Herrington       0      2023      \\N             \\N   \n",
       "1                        Ed Genesis       0      2019      \\N             \\N   \n",
       "2                  Aikens vs. Brown       0      2023      \\N             \\N   \n",
       "3  From Marshes to Mountain Heights       0      2002      \\N             21   \n",
       "4                   Orive vs. Stark       0      2023      \\N             \\N   \n",
       "\n",
       "       genre_1    genre_2          ingested_at  \n",
       "0   Reality-TV       None  2025-06-22 23:11:21  \n",
       "1  Documentary       None  2025-06-22 23:11:21  \n",
       "2   Reality-TV       None  2025-06-22 23:11:21  \n",
       "3       Action  Adventure  2025-06-22 23:11:21  \n",
       "4   Reality-TV       None  2025-06-22 23:11:21  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #✅ Vectorized UDFs leverage Arrow for better performance.\n",
    "\n",
    "# ✅ Cell 8: Use Arrow for toPandas conversion\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "title_basics.limit(5).toPandas()\n",
    "# ✅ Arrow accelerates PySpark to Pandas conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65feb180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ Cell 9: Bucketing vs Partitioning\n",
    "bucketed = title_ratings.write.bucketBy(8, \"tconst\").sortBy(\"averageRating\").saveAsTable(\"bucketed_ratings\")\n",
    "partitioned = title_ratings.write.partitionBy(\"averageRating\").parquet(\"/tmp/partitioned_ratings\")\n",
    "# ✅ Bucketing helps with join performance; partitioning with scan performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12181457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/23 00:48:54 WARN MemoryStore: Not enough space to cache broadcast_37 in memory! (computed 1760.0 MiB so far)\n",
      "25/06/23 00:48:54 WARN BlockManager: Persisting block broadcast_37 to disk instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------------------+\n",
      "|   tconst|averageRating|        primaryTitle|\n",
      "+---------+-------------+--------------------+\n",
      "|tt0000001|          5.7|          Carmencita|\n",
      "|tt0000002|          5.5|Le clown et ses c...|\n",
      "|tt0000003|          6.5|        Poor Pierrot|\n",
      "|tt0000004|          5.3|         Un bon bock|\n",
      "|tt0000005|          6.2|    Blacksmith Scene|\n",
      "+---------+-------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/23 00:49:01 WARN MemoryStore: Not enough space to cache broadcast_37 in memory! (computed 1760.0 MiB so far)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ Cell 10: Broadcast Join\n",
    "from pyspark.sql.functions import broadcast\n",
    "joined_df = title_ratings.join(broadcast(title_basics), on=\"tconst\")\n",
    "joined_df.select(\"tconst\", \"averageRating\", \"primaryTitle\").show(5)\n",
    "# ✅ Broadcast join avoids shuffle for small tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ff07f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ Cell 11: Skew Handling (Salting)\n",
    "from pyspark.sql.functions import monotonically_increasing_id, concat_ws\n",
    "skewed = title_ratings.withColumn(\"salt\", (monotonically_increasing_id() % 5))\n",
    "# Use salt key to distribute skewed join keys\n",
    "# ✅ Useful for reducing skew during joins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "977030fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+-------+-------------------+\n",
      "|    tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|    genre_1|genre_2|        ingested_at|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+-------+-------------------+\n",
      "|tt32444915|    movie|Lightning in a Bo...|Lightning in a Bo...|      0|       \\N|     \\N|            90|Documentary|   NULL|2025-06-22 23:11:21|\n",
      "|tt32444916|    movie|     A Night of Fate|     A Night of Fate|      0|     2024|     \\N|            54|      Drama|   NULL|2025-06-22 23:11:21|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+-------+-------------------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ Cell 12: Checkpointing\n",
    "spark.sparkContext.setCheckpointDir(\"/tmp/spark_checkpoints\")\n",
    "checkpointed = title_basics.filter(\"titleType = 'movie'\").checkpoint()\n",
    "checkpointed.show(2)\n",
    "# ✅ Avoid recomputation by checkpointing intermediate RDDs.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+\n",
      "|    tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|    genre_1|  genre_2|        ingested_at|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+\n",
      "|tt32444893|tvEpisode|McCraw vs. Herrin...|McCraw vs. Herrin...|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|\n",
      "|tt32444895|tvEpisode|          Ed Genesis|          Ed Genesis|      0|     2019|     \\N|            \\N|Documentary|     NULL|2025-06-22 23:11:21|\n",
      "|tt32444899|tvEpisode|    Aikens vs. Brown|    Aikens vs. Brown|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|\n",
      "| tt3244490|tvEpisode|From Marshes to M...|From Marshes to M...|      0|     2002|     \\N|            21|     Action|Adventure|2025-06-22 23:11:21|\n",
      "|tt32444901|tvEpisode|     Orive vs. Stark|     Orive vs. Stark|      0|     2023|     \\N|            \\N| Reality-TV|     NULL|2025-06-22 23:11:21|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+-----------+---------+-------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ Cell 13: Speculative Execution\n",
    "# Already enabled in config, useful if a task is slow due to node slowness\n",
    "# Cannot demo directly but improves reliability in real clusters\n",
    "# ✅ Helps avoid straggler tasks in large distributed jobs.\n",
    "# ✅ Cell 14: Caching\n",
    "title_basics.cache()\n",
    "title_basics.count()  # Trigger cache\n",
    "title_basics.show(5)\n",
    "# ✅ Caching avoids recomputation, speeding up repeated access to the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9c6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|averageRating|count|\n",
      "+-------------+-----+\n",
      "|          7.2|59762|\n",
      "|          7.4|57046|\n",
      "|          7.6|56657|\n",
      "|          7.8|55104|\n",
      "|          7.0|54131|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# ✅ Cell 15: Data Skew Handling\n",
    "from pyspark.sql.functions import col, count\n",
    "skewed_counts = title_ratings.groupBy(\"averageRating\").agg(count(\"*\").alias(\"count\")) \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "skewed_counts.show(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bba053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|    tconst|        primaryTitle|\n",
      "+----------+--------------------+\n",
      "|tt32444915|Lightning in a Bo...|\n",
      "|tt32444916|     A Night of Fate|\n",
      "|tt32444973|Mysterious Origin...|\n",
      "|tt32445107|             The Ten|\n",
      "| tt3244512|   Charlie's Country|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# ✅ Identify skewed data distributions to optimize joins and aggregations.\n",
    "# ✅ Cell 16: Adaptive Query Execution\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "# This is already set in the custom config\n",
    "# Adaptive Query Execution optimizes query plans based on runtime statistics.\n",
    "# ✅ Cell 17: Dynamic Partition Pruning\n",
    "# Already enabled in config, useful for optimizing joins with partitioned tables\n",
    "# Cannot demo directly but improves join performance with partitioned data\n",
    "# ✅ Dynamic partition pruning optimizes joins by pruning unnecessary partitions at runtime.\n",
    "# ✅ Cell 18: DataFrame API vs RDD API\n",
    "# DataFrame API is optimized and provides better performance than RDD API\n",
    "# Example: Using DataFrame API for filtering\n",
    "filtered_df = title_basics.filter(col(\"titleType\") == \"movie\").select(\"tconst\", \"primaryTitle\")\n",
    "filtered_df.show(5)\n",
    "# ✅ DataFrame API leverages Catalyst optimizer for better performance.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc988d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6152f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
